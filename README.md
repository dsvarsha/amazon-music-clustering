# ğŸ¶ Amazon Music Clustering using Unsupervised Machine Learning  
### ğŸ“Œ A Data Science Project by Varsha S  
Unsupervised ML | K-Means | PCA | Data Visualization | Music Analytics

---

## ğŸ“ Project Overview  
With millions of tracks on platforms like Amazon Music, manually categorizing songs into genres or moods is nearly impossible.  
This project uses **Unsupervised Machine Learning (K-Means Clustering)** to automatically group songs based on their **audio characteristics**, revealing natural musical clusters such as:

- ğŸ”Š Energetic / Dance tracks  
- ğŸ§ Acoustic / Chill songs  
- ğŸ—£ï¸ Speech-heavy vocal tracks  

The goal is to show how audio features can be used to understand music similarity without needing labels.

---

## ğŸ¯ Problem Statement  
The aim of this project is to **cluster Amazon Music songs** using numerical audio features like **tempo, energy, danceability, loudness, valence**, etc., and identify meaningful patterns in the dataset.

Clustering helps streaming platforms with:  
âœ” Personalized playlist generation  
âœ” Better music recommendations  
âœ” Identifying listener preferences  
âœ” Mood/genre discovery automation  

---

## ğŸ“‚ Dataset  
The dataset (`single_genre_artists.csv`) includes **95,837 songs** with 23 columns such as:  
- `danceability`, `energy`, `loudness`, `speechiness`,  
- `acousticness`, `instrumentalness`, `tempo`, `valence`,  
- metadata like artist name, song ID, release date, etc.

Only the **audio features** were used for clustering.

---

## ğŸ§  Project Workflow  
### **1ï¸âƒ£ Data Exploration (EDA)**  
- Checked missing values (none)  
- Verified data types and distributions  
- Identified 10 key audio features for clustering  

### **2ï¸âƒ£ Preprocessing & Feature Scaling**  
Selected features:  
danceability, energy, loudness, speechiness,
acousticness, instrumentalness, liveness,
valence, tempo, duration_ms
Scaled data using `StandardScaler`.

### **3ï¸âƒ£ PCA Visualization**  
Applied **PCA (2 components)** to visualize high-dimensional audio data in 2D space.

### **4ï¸âƒ£ Choosing Best K (Elbow + Silhouette)**  
- Elbow Method suggested k â‰ˆ 3â€“5  
- Silhouette Score was highest at **k = 3**  
â¡ï¸ Final model used **3 clusters**

### **5ï¸âƒ£ K-Means Clustering**  
Performed K-Means with `k = 3` and added cluster labels to dataset.

### **6ï¸âƒ£ Cluster Profiling & Visualization**  
Created visualizations:  
- Elbow curve  
- Silhouette scores  
- PCA scatter plot  
- Cluster mean bar chart  
- Radar chart  
- Feature boxplots  
- Tempo distributions  

---

## ğŸ” Cluster Interpretation  
Based on feature profiles, the model identified **3 natural clusters**:

### ğŸ¤ **Cluster 0 â€“ Speech-Heavy / Vocal-Rich Tracks**  
- Highest speechiness  
- Medium energy & danceability  
- Shorter duration  
ğŸ’¡ *Represents rap-like, talk-heavy, spoken-word style music*

### ğŸ¸ **Cluster 1 â€“ Acoustic / Calm / Emotional Songs**  
- Highest acousticness  
- Lowest energy  
- Softer mood (low valence)  
ğŸ’¡ *Represents chill, soft, emotional, acoustic tracks*

### âš¡ **Cluster 2 â€“ Energetic / Happy Dance-Pop Tracks**  
- Highest energy  
- Loudest songs  
- Fast tempo  
- Highest valence (happy mood)  
ğŸ’¡ *Represents upbeat, energetic, dance-style tracks*

---

## ğŸ“Š Visualizations Included  
All graphs are saved in the repository:  
- `elbow_method.png`  
- `silhouette_scores.png`  
- `pca_scatter_labeled.png`  
- `cluster_means_bar.png`  
- `cluster_means_radar.png`  
- `feature_boxplots.png`  
- `tempo_hist_by_cluster.png`

---

## ğŸ“ Repository Structure  
ğŸ“¦ amazon-music-clustering
â”œâ”€â”€ step1_eda.py
â”œâ”€â”€ step2_feature_selection.py
â”œâ”€â”€ step3_pca.py
â”œâ”€â”€ step4_kmeans.py
â”œâ”€â”€ step5_cluster_analysis.py
â”œâ”€â”€ step6_visualizations.py
â”œâ”€â”€ clustered_songs.csv
â”œâ”€â”€ cluster_profiles.csv
â”œâ”€â”€ top_songs_per_cluster.csv
â”œâ”€â”€ elbow_method.png
â”œâ”€â”€ pca_scatter_labeled.png
â”œâ”€â”€ cluster_means_bar.png
â”œâ”€â”€ cluster_means_radar.png
â”œâ”€â”€ feature_boxplots.png
â””â”€â”€ tempo_hist_by_cluster.png


---

## ğŸš€ How to Run the Project  
1. Clone the repository:  

---

## ğŸš€ How to Run the Project  
1. Clone the repository:  

---

## ğŸš€ How to Run the Project  
1. Clone the repository:  
git clone https://github.com/dsvarsha/amazon-music-clustering.git

2. Install required packages:  
pip install pandas numpy scikit-learn matplotlib seaborn


3. Run clustering scripts:  
python step1_eda.py
python step2_feature_selection.py
python step3_pca.py
python step4_kmeans.py
python step5_cluster_analysis.py
python step6_visualizations.py


---

## ğŸ“Œ Conclusion  
This project successfully demonstrates how unsupervised ML can uncover hidden music patterns using audio features. It provides valuable insights for:

- Music recommendation systems  
- Mood-based playlist creation  
- Artist/song similarity discovery  
- Audio-based segmentation  

---

## âœ¨ Author  
**Varsha Suresh**  
ğŸ“ Data Science & Machine Learning Enthusiast  
ğŸ“§ varshasuresh0708@gmail.com  
ğŸ”— GitHub: https://github.com/dsvarsha  

